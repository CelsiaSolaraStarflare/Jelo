{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df1fe52f",
   "metadata": {},
   "source": [
    "# Training Machine Learning Models for Commodity Export Forecasting\n",
    "\n",
    "This notebook demonstrates the process of training machine learning models to forecast commodity exports based on temporal, categorical, and geographical trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e3e4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (1.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\osmon\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch pandas numpy scikit-learn matplotlib seaborn transformers datasets accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70664ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4beb8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110711 entries, 0 to 110710\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                          Non-Null Count   Dtype \n",
      "---  ------                                          --------------   ----- \n",
      " 0   State                                           110711 non-null  object\n",
      " 1   Commodity                                       110711 non-null  object\n",
      " 2   Country                                         110711 non-null  object\n",
      " 3   Time                                            110711 non-null  object\n",
      " 4   Vessel Value ($US)                              110711 non-null  object\n",
      " 5   Containerized Vessel Total Exports Value ($US)  104171 non-null  object\n",
      " 6   Vessel SWT (kg)                                 110709 non-null  object\n",
      " 7   Containerized Vessel Total Exports SWT (kg)     104170 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vessel Value ($US)</th>\n",
       "      <th>Containerized Vessel Total Exports Value ($US)</th>\n",
       "      <th>Vessel SWT (kg)</th>\n",
       "      <th>Containerized Vessel Total Exports SWT (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Jul-16</td>\n",
       "      <td>7,185</td>\n",
       "      <td>7,185</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Feb-20</td>\n",
       "      <td>13,792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - South</td>\n",
       "      <td>Jun-18</td>\n",
       "      <td>15,087</td>\n",
       "      <td>15,087</td>\n",
       "      <td>1,422</td>\n",
       "      <td>1,422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - Other</td>\n",
       "      <td>Mar-08</td>\n",
       "      <td>12,515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,958</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - Other</td>\n",
       "      <td>Jul-08</td>\n",
       "      <td>12,135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20,284</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State        Commodity       Country    Time Vessel Value ($US)  \\\n",
       "0  Illinois  01 Live Animals        Africa  Jul-16              7,185   \n",
       "1  Illinois  01 Live Animals        Africa  Feb-20             13,792   \n",
       "2  Illinois  01 Live Animals  Asia - South  Jun-18             15,087   \n",
       "3  Illinois  01 Live Animals  Asia - Other  Mar-08             12,515   \n",
       "4  Illinois  01 Live Animals  Asia - Other  Jul-08             12,135   \n",
       "\n",
       "  Containerized Vessel Total Exports Value ($US) Vessel SWT (kg)  \\\n",
       "0                                          7,185               6   \n",
       "1                                            NaN             494   \n",
       "2                                         15,087           1,422   \n",
       "3                                            NaN          19,958   \n",
       "4                                            NaN          20,284   \n",
       "\n",
       "  Containerized Vessel Total Exports SWT (kg)  \n",
       "0                                           6  \n",
       "1                                         NaN  \n",
       "2                                       1,422  \n",
       "3                                         NaN  \n",
       "4                                         NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and explore the dataset\n",
    "file_path = 'c:/Users/osmon/Desktop/custom_data/export/Illinois.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(file_path, header=2)\n",
    "\n",
    "# Clean up column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26c31a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after cleaning:\n",
      "State                                                     object\n",
      "Commodity                                                 object\n",
      "Country                                                   object\n",
      "Time                                              datetime64[ns]\n",
      "Vessel Value ($US)                                         int64\n",
      "Containerized Vessel Total Exports Value ($US)             int64\n",
      "Vessel SWT (kg)                                            int64\n",
      "Containerized Vessel Total Exports SWT (kg)                int64\n",
      "dtype: object\n",
      "\n",
      "Dataset shape: (104170, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Country</th>\n",
       "      <th>Time</th>\n",
       "      <th>Vessel Value ($US)</th>\n",
       "      <th>Containerized Vessel Total Exports Value ($US)</th>\n",
       "      <th>Vessel SWT (kg)</th>\n",
       "      <th>Containerized Vessel Total Exports SWT (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>7185</td>\n",
       "      <td>7185</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - South</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>15087</td>\n",
       "      <td>15087</td>\n",
       "      <td>1422</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - Other</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>5560</td>\n",
       "      <td>5560</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - Other</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>123178</td>\n",
       "      <td>123178</td>\n",
       "      <td>1142</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>01 Live Animals</td>\n",
       "      <td>Asia - Other</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>85860</td>\n",
       "      <td>85860</td>\n",
       "      <td>1681</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State        Commodity       Country       Time  Vessel Value ($US)  \\\n",
       "0  Illinois  01 Live Animals        Africa 2016-07-01                7185   \n",
       "2  Illinois  01 Live Animals  Asia - South 2018-06-01               15087   \n",
       "5  Illinois  01 Live Animals  Asia - Other 2009-09-01                5560   \n",
       "6  Illinois  01 Live Animals  Asia - Other 2011-12-01              123178   \n",
       "7  Illinois  01 Live Animals  Asia - Other 2012-01-01               85860   \n",
       "\n",
       "   Containerized Vessel Total Exports Value ($US)  Vessel SWT (kg)  \\\n",
       "0                                            7185                6   \n",
       "2                                           15087             1422   \n",
       "5                                            5560             1236   \n",
       "6                                          123178             1142   \n",
       "7                                           85860             1681   \n",
       "\n",
       "   Containerized Vessel Total Exports SWT (kg)  \n",
       "0                                            6  \n",
       "2                                         1422  \n",
       "5                                         1236  \n",
       "6                                         1142  \n",
       "7                                         1681  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Remove problematic rows if necessary\n",
    "if df.iloc[-1]['State'] == '98 Special Classification Provisions, Nesoi':\n",
    "    df = df.iloc[:-1]\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert 'Time' column to datetime format if applicable\n",
    "if 'Time' in df.columns:\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%b-%y')\n",
    "\n",
    "# Clean and convert ALL numeric columns (detect and fix comma-separated numbers)\n",
    "exclude_cols = ['Time', 'State', 'Commodity', 'Country']\n",
    "for col in df.columns:\n",
    "    if col not in exclude_cols:\n",
    "        # Check if column contains string values that might be numbers with commas\n",
    "        if df[col].dtype == 'object':\n",
    "            # Try to clean and convert to numeric\n",
    "            df[col] = df[col].astype(str).str.replace(',', '').replace('', '0').replace('nan', '0')\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif df[col].dtype in ['int64', 'float64']:\n",
    "            # Already numeric, but ensure no missing values\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Handle any remaining missing values after conversion\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Data types after cleaning:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "\n",
    "# Display the cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed8959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Ensure 'Time' column exists before proceeding\n",
    "if 'Time' in df.columns:\n",
    "    # Generate temporal features\n",
    "    df['Year'] = pd.DatetimeIndex(df['Time']).year\n",
    "    df['Month'] = pd.DatetimeIndex(df['Time']).month\n",
    "\n",
    "    # Generate lag features\n",
    "    for lag in [1, 2, 3, 6, 12]:\n",
    "        df[f'export_value_lag_{lag}'] = df['Vessel Value ($US)'].shift(lag)\n",
    "        df[f'export_weight_lag_{lag}'] = df['Vessel SWT (kg)'].shift(lag)\n",
    "\n",
    "    # Generate rolling statistics\n",
    "    for window in [3, 6, 12]:\n",
    "        df[f'export_value_rolling_mean_{window}'] = df['Vessel Value ($US)'].rolling(window).mean()\n",
    "        df[f'export_value_rolling_std_{window}'] = df['Vessel Value ($US)'].rolling(window).std()\n",
    "\n",
    "    # Drop rows with NaN values generated by lagging\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Display the dataset with new features\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"Error: 'Time' column is missing from the dataset.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa2fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to prepare data for LSTM\n",
    "def prepare_lstm_data(df, sequence_length=12):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM training by creating sequences\n",
    "    Args:\n",
    "        df: DataFrame with time series data\n",
    "        sequence_length: Number of time steps to look back\n",
    "    Returns:\n",
    "        X: Input sequences (samples, time_steps, features)\n",
    "        y_value: Target values for vessel value\n",
    "        y_weight: Target values for vessel weight\n",
    "        feature_cols: List of feature column names\n",
    "        valid_indices: Indices of valid samples\n",
    "    \"\"\"\n",
    "    # Sort by time to ensure proper sequence order\n",
    "    if 'Time' in df.columns:\n",
    "        df_sorted = df.sort_values('Time').reset_index(drop=True)\n",
    "    else:\n",
    "        df_sorted = df.copy()\n",
    "    \n",
    "    # Select numeric features for training (exclude non-numeric and target columns)\n",
    "    exclude_cols = ['Time', 'State', 'Commodity', 'Country']\n",
    "    feature_cols = [col for col in df_sorted.columns if col not in exclude_cols]\n",
    "    \n",
    "    print(f\"Selected feature columns: {feature_cols}\")\n",
    "    print(f\"Total features: {len(feature_cols)}\")\n",
    "    \n",
    "    # Ensure we have the target columns\n",
    "    if 'Vessel Value ($US)' not in feature_cols or 'Vessel SWT (kg)' not in feature_cols:\n",
    "        raise ValueError(\"Target columns 'Vessel Value ($US)' and 'Vessel SWT (kg)' not found\")\n",
    "    \n",
    "    # Create feature matrix\n",
    "    features = df_sorted[feature_cols].values\n",
    "    \n",
    "    # Check for sufficient data\n",
    "    if len(features) <= sequence_length:\n",
    "        raise ValueError(f\"Not enough data points. Need at least {sequence_length + 1}, got {len(features)}\")\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y_value, y_weight = [], [], []\n",
    "    valid_indices = []\n",
    "    \n",
    "    value_idx = feature_cols.index('Vessel Value ($US)')\n",
    "    weight_idx = feature_cols.index('Vessel SWT (kg)')\n",
    "    \n",
    "    for i in range(sequence_length, len(features)):\n",
    "        # Input sequence (past sequence_length time steps)\n",
    "        X.append(features[i-sequence_length:i])\n",
    "        \n",
    "        # Target values (current time step)\n",
    "        y_value.append(features[i, value_idx])\n",
    "        y_weight.append(features[i, weight_idx])\n",
    "        valid_indices.append(i)\n",
    "    \n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y_value = np.array(y_value, dtype=np.float32)\n",
    "    y_weight = np.array(y_weight, dtype=np.float32)\n",
    "    \n",
    "    print(f\"Created {len(X)} sequences\")\n",
    "    print(f\"Sequence shape: {X.shape}\")\n",
    "    \n",
    "    return X, y_value, y_weight, feature_cols, valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a6db85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Selected feature columns: ['Vessel Value ($US)', 'Containerized Vessel Total Exports Value ($US)', 'Vessel SWT (kg)', 'Containerized Vessel Total Exports SWT (kg)', 'Year', 'Month', 'export_value_lag_1', 'export_weight_lag_1', 'export_value_lag_2', 'export_weight_lag_2', 'export_value_lag_3', 'export_weight_lag_3', 'export_value_lag_6', 'export_weight_lag_6', 'export_value_lag_12', 'export_weight_lag_12', 'export_value_rolling_mean_3', 'export_value_rolling_std_3', 'export_value_rolling_mean_6', 'export_value_rolling_std_6', 'export_value_rolling_mean_12', 'export_value_rolling_std_12']\n",
      "Total features: 22\n",
      "Created 104146 sequences\n",
      "Sequence shape: (104146, 12, 22)\n",
      "Data shape: X=(104146, 12, 22), y_value=(104146,), y_weight=(104146,)\n",
      "Features used: ['Vessel Value ($US)', 'Containerized Vessel Total Exports Value ($US)', 'Vessel SWT (kg)', 'Containerized Vessel Total Exports SWT (kg)', 'Year', 'Month', 'export_value_lag_1', 'export_weight_lag_1', 'export_value_lag_2', 'export_weight_lag_2', 'export_value_lag_3', 'export_weight_lag_3', 'export_value_lag_6', 'export_weight_lag_6', 'export_value_lag_12', 'export_weight_lag_12', 'export_value_rolling_mean_3', 'export_value_rolling_std_3', 'export_value_rolling_mean_6', 'export_value_rolling_std_6', 'export_value_rolling_mean_12', 'export_value_rolling_std_12']\n",
      "Created 104146 sequences\n",
      "Sequence shape: (104146, 12, 22)\n",
      "Data shape: X=(104146, 12, 22), y_value=(104146,), y_weight=(104146,)\n",
      "Features used: ['Vessel Value ($US)', 'Containerized Vessel Total Exports Value ($US)', 'Vessel SWT (kg)', 'Containerized Vessel Total Exports SWT (kg)', 'Year', 'Month', 'export_value_lag_1', 'export_weight_lag_1', 'export_value_lag_2', 'export_weight_lag_2', 'export_value_lag_3', 'export_weight_lag_3', 'export_value_lag_6', 'export_weight_lag_6', 'export_value_lag_12', 'export_weight_lag_12', 'export_value_rolling_mean_3', 'export_value_rolling_std_3', 'export_value_rolling_mean_6', 'export_value_rolling_std_6', 'export_value_rolling_mean_12', 'export_value_rolling_std_12']\n",
      "Model input size: 22\n",
      "Model initialized on cpu\n",
      "Model input size: 22\n",
      "Model initialized on cpu\n",
      "Epoch [1/10], Loss: 676488890256760.0000\n",
      "Epoch [1/10], Loss: 676488890256760.0000\n",
      "Epoch [2/10], Loss: 676495637355298.2500\n",
      "Epoch [2/10], Loss: 676495637355298.2500\n",
      "Epoch [3/10], Loss: 676487204873865.6250\n",
      "Epoch [3/10], Loss: 676487204873865.6250\n",
      "Epoch [4/10], Loss: 676600481102538.1250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m X_batch, y_value_batch, y_weight_batch = batch\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m value_pred, weight_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m loss_value = criterion(value_pred, y_value_batch.unsqueeze(\u001b[32m1\u001b[39m))\n\u001b[32m     68\u001b[39m loss_weight = criterion(weight_pred, y_weight_batch.unsqueeze(\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mLSTMModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     out = out[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# Take the last output\u001b[39;00m\n\u001b[32m     42\u001b[39m     value = \u001b[38;5;28mself\u001b[39m.fc_value(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train LSTM Model using PyTorch with CUDA support\n",
    "# Prepare data for PyTorch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Force CUDA usage if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"CUDA is not available, falling back to CPU\")\n",
    "\n",
    "sequence_length = 12\n",
    "X, y_value, y_weight, feature_cols, indices = prepare_lstm_data(df, sequence_length=sequence_length)\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y_value={y_value.shape}, y_weight={y_weight.shape}\")\n",
    "print(f\"Features used: {feature_cols}\")\n",
    "\n",
    "X_train, X_test, y_value_train, y_value_test, y_weight_train, y_weight_test = train_test_split(\n",
    "    X, y_value, y_weight, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert data to PyTorch tensors and move to GPU\n",
    "print(\"Moving data to GPU...\")\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_value_train_tensor = torch.tensor(y_value_train, dtype=torch.float32).to(device)\n",
    "y_weight_train_tensor = torch.tensor(y_weight_train, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_value_test_tensor = torch.tensor(y_value_test, dtype=torch.float32).to(device)\n",
    "y_weight_test_tensor = torch.tensor(y_weight_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"Training data moved to: {X_train_tensor.device}\")\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(X_train_tensor, y_value_train_tensor, y_weight_train_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc_value = nn.Linear(hidden_size, output_size)\n",
    "        self.fc_weight = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out[:, -1, :])  # Take the last output and apply dropout\n",
    "        value = self.fc_value(out)\n",
    "        weight = self.fc_weight(out)\n",
    "        return value, weight\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X.shape[2]  # Number of features (dynamic based on actual data)\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.L1Loss()  # Using MAE (L1Loss) instead of MSE\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model input size: {input_size}\")\n",
    "print(f\"Model initialized on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "print(\"Using MAE (L1Loss) as loss function\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA memory after model creation: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 20  # Increased epochs for better training\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X_batch, y_value_batch, y_weight_batch = batch\n",
    "\n",
    "        # Forward pass\n",
    "        value_pred, weight_pred = model(X_batch)\n",
    "        loss_value = criterion(value_pred, y_value_batch.unsqueeze(1))\n",
    "        loss_weight = criterion(weight_pred, y_weight_batch.unsqueeze(1))\n",
    "        loss = loss_value + loss_weight\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    \n",
    "    # Evaluation on test set every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            value_pred_test, weight_pred_test = model(X_test_tensor)\n",
    "            test_loss_value = criterion(value_pred_test, y_value_test_tensor.unsqueeze(1))\n",
    "            test_loss_weight = criterion(weight_pred_test, y_weight_test_tensor.unsqueeze(1))\n",
    "            test_loss = test_loss_value + test_loss_weight\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss (MAE): {avg_loss:.4f}, Test Loss (MAE): {test_loss.item():.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss (MAE): {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    value_pred_test, weight_pred_test = model(X_test_tensor)\n",
    "    \n",
    "    # Move predictions back to CPU for evaluation\n",
    "    value_pred_np = value_pred_test.cpu().numpy().flatten()\n",
    "    weight_pred_np = weight_pred_test.cpu().numpy().flatten()\n",
    "    y_value_test_np = y_value_test_tensor.cpu().numpy()\n",
    "    y_weight_test_np = y_weight_test_tensor.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    value_mae = mean_absolute_error(y_value_test_np, value_pred_np)\n",
    "    value_mse = mean_squared_error(y_value_test_np, value_pred_np)\n",
    "    value_r2 = r2_score(y_value_test_np, value_pred_np)\n",
    "    \n",
    "    weight_mae = mean_absolute_error(y_weight_test_np, weight_pred_np)\n",
    "    weight_mse = mean_squared_error(y_weight_test_np, weight_pred_np)\n",
    "    weight_r2 = r2_score(y_weight_test_np, weight_pred_np)\n",
    "    \n",
    "    print(\"\\n=== Final Model Performance ===\")\n",
    "    print(f\"Vessel Value - MAE: {value_mae:.2f}, MSE: {value_mse:.2f}, R²: {value_r2:.4f}\")\n",
    "    print(f\"Vessel Weight - MAE: {weight_mae:.2f}, MSE: {weight_mse:.2f}, R²: {weight_r2:.4f}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nFinal CUDA memory usage: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
